{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR_y9gkjbYks"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Ruta base en Google Drive\n",
        "base_dir = '/content/drive/MyDrive/sis421/dataset'\n",
        "\n",
        "# Rutas de imágenes y etiquetas\n",
        "images_dir = os.path.join(base_dir, 'images')\n",
        "annotations_file = os.path.join(base_dir, 'annotations.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Cargar el archivo de anotaciones\n",
        "with open(annotations_file, 'r') as f:\n",
        "    annotations = json.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "UhVSGkD8eMEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class MedicinalPlantsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, annotations, images_dir, transforms=None):\n",
        "        self.annotations = annotations\n",
        "        self.images_dir = images_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        annotation = self.annotations[idx]\n",
        "        img_path = os.path.join(self.images_dir, annotation[\"file_name\"])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Bounding boxes y etiquetas\n",
        "        boxes = torch.tensor(annotation[\"boxes\"], dtype=torch.float32)\n",
        "        labels = torch.tensor(annotation[\"labels\"], dtype=torch.int64)\n",
        "\n",
        "        target = {\"boxes\": boxes, \"labels\": labels}\n",
        "\n",
        "        if self.transforms:\n",
        "            img, target = self.transforms(img, target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n"
      ],
      "metadata": {
        "id": "s8W1n1vZeSae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = get_model(num_classes)\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "yND4x4rfeWKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_annotations, val_annotations = train_test_split(annotations, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = MedicinalPlantsDataset(train_annotations, images_dir)\n",
        "val_dataset = MedicinalPlantsDataset(val_annotations, images_dir)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# Entrenar\n",
        "num_epochs = 10\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, targets in tqdm(train_loader):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Adelante y cálculo de pérdida\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        epoch_loss += losses.item()\n",
        "\n",
        "        # Atrás y optimización\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "nevR61PJeYwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/medicinal_plants_detector.pth'\n",
        "torch.save(model.state_dict(), output_path)\n",
        "print(f\"Modelo guardado en {output_path}\")\n"
      ],
      "metadata": {
        "id": "8NgUJRnyeqT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_image_path = '/content/drive/MyDrive/sis421/dataset/images/test_image.jpg'\n",
        "\n",
        "with torch.no_grad():\n",
        "    img = Image.open(test_image_path).convert(\"RGB\")\n",
        "    transform = torchvision.transforms.ToTensor()\n",
        "    img_tensor = transform(img).to(device)\n",
        "\n",
        "    output = model([img_tensor])  # Predicción\n",
        "    print(output)  # Muestra las detecciones\n"
      ],
      "metadata": {
        "id": "YJpFZKcue2Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Dibujar las detecciones\n",
        "def draw_boxes(image_path, boxes):\n",
        "    img = cv2.imread(image_path)\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "    return img\n",
        "\n",
        "# Visualizar\n",
        "img_with_boxes = draw_boxes(test_image_path, output[0]['boxes'].cpu().numpy())\n",
        "plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pcxyQYQte23-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}